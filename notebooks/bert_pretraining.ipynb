{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee9ffdbd-ce68-4918-b9d3-4ab7f88a70e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./bert_pretrain_env/lib/python3.10/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from seaborn) (2.3.0)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [seaborn]m6/7\u001b[0m [seaborn]ib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.1 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3 seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "349a6f7e-00d8-436f-ae63-8221e6202dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./bert_pretrain_env/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./bert_pretrain_env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5fad97-390d-4f7f-a5d9-4dd0ce330261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: datasets in ./bert_pretrain_env/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./bert_pretrain_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./bert_pretrain_env/lib/python3.10/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in ./bert_pretrain_env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./bert_pretrain_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf94f86-7478-4e50-9d1f-274a812e502a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in ./bert_pretrain_env/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./bert_pretrain_env/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Collecting torch<2.7,>=2.1 (from transformers[torch])\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./bert_pretrain_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (1.1.3)\n",
      "Requirement already satisfied: networkx in ./bert_pretrain_env/lib/python3.10/site-packages (from torch<2.7,>=2.1->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch<2.7,>=2.1->transformers[torch]) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch<2.7,>=2.1->transformers[torch])\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from sympy==1.13.1->torch<2.7,>=2.1->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in ./bert_pretrain_env/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from jinja2->torch<2.7,>=2.1->transformers[torch]) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers[torch]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bert_pretrain_env/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.4.26)\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, accelerate\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.3.1\n",
      "\u001b[2K    Uninstalling triton-3.3.1:\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12━━\u001b[0m \u001b[32m 0/17\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.30m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.3:0m \u001b[32m 0/17\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]parselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.6.85:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu120m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:m━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.1m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.1:━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [accelerate]7\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.22.1 requires torch==2.7.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.7.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84038103-44a7-4152-8cb1-e3858438549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.52.4\n",
      "Uninstalling transformers-4.52.4:\n",
      "  Would remove:\n",
      "    /root/pretrain/bert_pretrain_env/bin/transformers\n",
      "    /root/pretrain/bert_pretrain_env/bin/transformers-cli\n",
      "    /root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/transformers-4.52.4.dist-info/*\n",
      "    /root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/transformers/*\n",
      "Proceed (Y/n)?   Successfully uninstalled transformers-4.52.4\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0af38a9-34d4-45a1-aa39-5039ce46fffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./bert_pretrain_env/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in ./bert_pretrain_env/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in ./bert_pretrain_env/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: torch in ./bert_pretrain_env/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./bert_pretrain_env/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./bert_pretrain_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./bert_pretrain_env/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Using cached triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from triton==3.3.1->torch) (80.3.1)\n",
      "Requirement already satisfied: six>=1.5 in ./bert_pretrain_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./bert_pretrain_env/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/16\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: triton 3.2.0[0m \u001b[32m 0/16\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling triton-3.2.0:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/16\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled triton-3.2.0━\u001b[0m \u001b[32m 0/16\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.4.127━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.4.127:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.4.127━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.4.127[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.4.127:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127━\u001b[0m \u001b[32m 2/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.5.147\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.5.147:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.5.147━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127 \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.1270m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.1270m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.4.1270m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu120m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.4.5.8━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.4.5.8:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8━━━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.3.1.1700m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.3.1.170:━━━━━━━━━━━━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.1.3━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.1.3:m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m12/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.1.0.70━━━\u001b[0m \u001b[32m12/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m12/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.700m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\u001b[0m \u001b[32m13/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.1.9:[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9━━\u001b[0m \u001b[32m13/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.6.0[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.6.0:━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m15/16\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.6.0━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m15/16\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [torch]m15/16\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b423d835-fc6a-4bc1-b92c-098d0ec668a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, RobertaForMaskedLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer, EarlyStoppingCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cccfdb7-8cec-4063-85d5-58258a202991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c7111f-240a-4bba-ac4b-78dfce345092",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 19\n",
    "random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05878694-2b70-458d-a620-ca6401d121fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"text\", data_files=\"data/asian_speech.txt\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b310834c-1065-4253-91f3-d385ae68d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 354611\n",
      "Validation size: 39402\n"
     ]
    }
   ],
   "source": [
    "split = dataset.train_test_split(test_size=0.1, seed=19)\n",
    "train_ds = split[\"train\"]\n",
    "val_ds = split[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Validation size:\", len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39657ad2-88a5-4383-80b7-eeda42578ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'this guy broke a cookie in half and gave it to her , expecting her to eat the other half .'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[5644]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d4a937e-f360-4fb5-81e9-25c948166212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74eaa00799414108b3b2bbd57f13f6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a4c2f6681b448495ef171bda8e7533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb3fcf621de45568ce0d06e1b545755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b7c66b94d947179ed695e2673d7ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3847fd977dc241c59c4d6b88235f7214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908d1ed668994a49a9cb2ad70cfae840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "roberta_mlm = RobertaForMaskedLM.from_pretrained(\"FacebookAI/roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98be7dfe-7f49-4ac4-83ae-fe44482a7ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb05b63cda94ed79a150bac34a5d6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/354611 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b482747968e4aa4b084006a5bb56894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/39402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "train_tokenised = train_ds.map(tokenize_text, batched=True, num_proc=8)\n",
    "val_tokenised = val_ds.map(tokenize_text, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a1f04e-f74b-435e-bdb4-f3a02511fdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'this guy broke a cookie in half and gave it to her , expecting her to eat the other half .',\n",
       " 'input_ids': [0,\n",
       "  9226,\n",
       "  2173,\n",
       "  2263,\n",
       "  10,\n",
       "  20931,\n",
       "  11,\n",
       "  457,\n",
       "  8,\n",
       "  851,\n",
       "  24,\n",
       "  7,\n",
       "  69,\n",
       "  2156,\n",
       "  4804,\n",
       "  69,\n",
       "  7,\n",
       "  3529,\n",
       "  5,\n",
       "  97,\n",
       "  457,\n",
       "  479,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenised[5644]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "056add2a-d97d-4586-9976-50228d9986f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fcbe5-f8da-4c92-ab59-af19479659b5",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ef6ae2-6c36-49b4-84ab-59229262324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/speech_roberta_mlm\",\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    eval_steps=150,\n",
    "    logging_steps=100,\n",
    "    save_steps=150,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    fp16=True,\n",
    "    logging_dir=\"logs/pretrain\",\n",
    "\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf354967-7af5-4ca1-a84f-a9df40a978b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97' max='522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 97/522 1:32:25 < 6:53:29, 0.02 it/s, Epoch 0.55/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mroberta_mlm,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping],\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#trainer.train(resume_from_checkpoint=True)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/transformers/trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2553\u001b[0m )\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2561\u001b[0m ):\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/transformers/trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3789\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/accelerate/accelerator.py:2469\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2469\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=roberta_mlm,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenised,\n",
    "    eval_dataset=val_tokenised,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84447e74-6ff4-438b-89bd-87a94edfb93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='522' max='522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [522/522 8:30:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.321800</td>\n",
       "      <td>2.112393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.083500</td>\n",
       "      <td>1.974543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.002500</td>\n",
       "      <td>1.901382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=522, training_loss=2.1095037569944886, metrics={'train_runtime': 30681.548, 'train_samples_per_second': 34.673, 'train_steps_per_second': 0.017, 'total_flos': 3.2627408238633384e+16, 'train_loss': 2.1095037569944886, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=roberta_mlm,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenised,\n",
    "    eval_dataset=val_tokenised,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "437f02fa-b01c-40fe-b1fa-75e94b0fbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_mlm.save_pretrained(\"pretrained/speech_roberta_mlm3\", from_pt=True)\n",
    "#roberta_mlm = RobertaForMaskedLM.from_pretrained(\"models/speech_roberta_mlm3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d722bf5a-1092-4b26-bb8a-7a0200809bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n",
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [696/696 2:49:36, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.975600</td>\n",
       "      <td>1.894618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=696, training_loss=0.48933035751868936, metrics={'train_runtime': 10235.9133, 'train_samples_per_second': 138.575, 'train_steps_per_second': 0.068, 'total_flos': 4.350922187012954e+16, 'train_loss': 0.48933035751868936, 'epoch': 4.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/speech_roberta_mlm\",\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # размеры батчей и оптимизатор\n",
    "    num_train_epochs=4, # было 3\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    fp16=True,\n",
    "    logging_dir=\"logs/pretrain\",\n",
    "\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=roberta_mlm,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenised,\n",
    "    eval_dataset=val_tokenised,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02b1d4-c467-422d-bc7a-e29484f45c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_mlm.save_pretrained(\"pretrained/speech_roberta_mlm4\", from_pt=True)\n",
    "#roberta_mlm.save_model(\"models/speech_roberta_mlm4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09dc3768-9cf7-4559-9114-d24548989ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n",
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [870/870 2:49:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>1.901085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=870, training_loss=0.38931653472198835, metrics={'train_runtime': 10225.5133, 'train_samples_per_second': 173.395, 'train_steps_per_second': 0.085, 'total_flos': 5.439243718454159e+16, 'train_loss': 0.38931653472198835, 'epoch': 5.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/speech_roberta_mlm\",\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    fp16=True,\n",
    "    logging_dir=\"logs/pretrain\",\n",
    "\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=roberta_mlm,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenised,\n",
    "    eval_dataset=val_tokenised,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "#trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1f49746-67d5-4b45-bb91-473763f448fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m roberta_mlm\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained/speech_roberta_mlm5\u001b[39m\u001b[38;5;124m\"\u001b[39m, from_pt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroberta_mlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/speech_roberta_mlm5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/serialization.py:964\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    961\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    965\u001b[0m         _save(\n\u001b[1;32m    966\u001b[0m             obj,\n\u001b[1;32m    967\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    970\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/serialization.py:828\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/serialization.py:792\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    786\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[1;32m    788\u001b[0m         )\n\u001b[1;32m    789\u001b[0m     )\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 792\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "roberta_mlm.save_pretrained(\"pretrained/speech_roberta_mlm5\", from_pt=True)\n",
    "torch.save(roberta_mlm.state_dict(), \"models/speech_roberta_mlm5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7c35bc8-51b6-4e32-a3c7-c311ca537e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b0c82fa-8116-4481-8276-9c74bde7057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(roberta_mlm.state_dict(), \"models/speech_roberta_mlm5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c18cab0-2539-4d2b-9086-853ade38f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pretrain/bert_pretrain_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [616/616 02:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.910383701324463,\n",
       " 'eval_runtime': 126.9117,\n",
       " 'eval_samples_per_second': 310.468,\n",
       " 'eval_steps_per_second': 4.854,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b52031b-9495-4ba8-b5a8-d4012cd0e608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 0.5775130842808157,\n",
       "  'grad_norm': 284565.0625,\n",
       "  'learning_rate': 9.9e-06,\n",
       "  'loss': 2.3218,\n",
       "  'step': 100},\n",
       " {'epoch': 0.8662696264212236,\n",
       "  'eval_loss': 2.1123931407928467,\n",
       "  'eval_runtime': 127.5784,\n",
       "  'eval_samples_per_second': 308.845,\n",
       "  'eval_steps_per_second': 4.828,\n",
       "  'step': 150},\n",
       " {'epoch': 1.1501534019130122,\n",
       "  'grad_norm': 283944.90625,\n",
       "  'learning_rate': 1.9900000000000003e-05,\n",
       "  'loss': 2.1928,\n",
       "  'step': 200},\n",
       " {'epoch': 1.7276664861938278,\n",
       "  'grad_norm': 254032.40625,\n",
       "  'learning_rate': 1.3850931677018635e-05,\n",
       "  'loss': 2.0835,\n",
       "  'step': 300},\n",
       " {'epoch': 1.7276664861938278,\n",
       "  'eval_loss': 1.9745430946350098,\n",
       "  'eval_runtime': 127.7302,\n",
       "  'eval_samples_per_second': 308.478,\n",
       "  'eval_steps_per_second': 4.823,\n",
       "  'step': 300},\n",
       " {'epoch': 2.3003068038260244,\n",
       "  'grad_norm': 239576.875,\n",
       "  'learning_rate': 7.639751552795032e-06,\n",
       "  'loss': 2.0025,\n",
       "  'step': 400},\n",
       " {'epoch': 2.589063345966432,\n",
       "  'eval_loss': 1.9013824462890625,\n",
       "  'eval_runtime': 127.6578,\n",
       "  'eval_samples_per_second': 308.653,\n",
       "  'eval_steps_per_second': 4.825,\n",
       "  'step': 450},\n",
       " {'epoch': 2.87781988810684,\n",
       "  'grad_norm': 247095.71875,\n",
       "  'learning_rate': 1.4285714285714286e-06,\n",
       "  'loss': 1.9908,\n",
       "  'step': 500},\n",
       " {'epoch': 3.450460205739036,\n",
       "  'grad_norm': 232039.125,\n",
       "  'learning_rate': 3.911290322580646e-06,\n",
       "  'loss': 1.9756,\n",
       "  'step': 600},\n",
       " {'epoch': 3.450460205739036,\n",
       "  'eval_loss': 1.8946179151535034,\n",
       "  'eval_runtime': 127.7768,\n",
       "  'eval_samples_per_second': 308.366,\n",
       "  'eval_steps_per_second': 4.821,\n",
       "  'step': 600},\n",
       " {'loss': 1.967,\n",
       "  'grad_norm': 251069.09375,\n",
       "  'learning_rate': 5.104477611940299e-06,\n",
       "  'epoch': 4.023100523371233,\n",
       "  'step': 700},\n",
       " {'eval_loss': 1.9010854959487915,\n",
       "  'eval_runtime': 127.7159,\n",
       "  'eval_samples_per_second': 308.513,\n",
       "  'eval_steps_per_second': 4.823,\n",
       "  'epoch': 4.31185706551164,\n",
       "  'step': 750},\n",
       " {'loss': 1.9539,\n",
       "  'grad_norm': 233244.140625,\n",
       "  'learning_rate': 2.119402985074627e-06,\n",
       "  'epoch': 4.600613607652049,\n",
       "  'step': 800},\n",
       " {'train_runtime': 10225.5133,\n",
       "  'train_samples_per_second': 173.395,\n",
       "  'train_steps_per_second': 0.085,\n",
       "  'total_flos': 5.439243718454159e+16,\n",
       "  'train_loss': 0.38931653472198835,\n",
       "  'epoch': 5.0,\n",
       "  'step': 870},\n",
       " {'eval_loss': 1.910383701324463,\n",
       "  'eval_runtime': 126.9117,\n",
       "  'eval_samples_per_second': 310.468,\n",
       "  'eval_steps_per_second': 4.854,\n",
       "  'epoch': 5.0,\n",
       "  'step': 870}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68e93838-3954-4041-940a-bfa5dc780ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/speech_roberta_mlm/checkpoint-600'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.best_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "853c6c0e-db72-4d73-8154-e0ace49edd0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 0.5775130842808157,\n",
       "  'grad_norm': 284565.0625,\n",
       "  'learning_rate': 9.9e-06,\n",
       "  'loss': 2.3218,\n",
       "  'step': 100},\n",
       " {'epoch': 0.8662696264212236,\n",
       "  'eval_loss': 2.1123931407928467,\n",
       "  'eval_runtime': 127.5784,\n",
       "  'eval_samples_per_second': 308.845,\n",
       "  'eval_steps_per_second': 4.828,\n",
       "  'step': 150},\n",
       " {'epoch': 1.1501534019130122,\n",
       "  'grad_norm': 283944.90625,\n",
       "  'learning_rate': 1.9900000000000003e-05,\n",
       "  'loss': 2.1928,\n",
       "  'step': 200},\n",
       " {'epoch': 1.7276664861938278,\n",
       "  'grad_norm': 254032.40625,\n",
       "  'learning_rate': 1.3850931677018635e-05,\n",
       "  'loss': 2.0835,\n",
       "  'step': 300},\n",
       " {'epoch': 1.7276664861938278,\n",
       "  'eval_loss': 1.9745430946350098,\n",
       "  'eval_runtime': 127.7302,\n",
       "  'eval_samples_per_second': 308.478,\n",
       "  'eval_steps_per_second': 4.823,\n",
       "  'step': 300},\n",
       " {'epoch': 2.3003068038260244,\n",
       "  'grad_norm': 239576.875,\n",
       "  'learning_rate': 7.639751552795032e-06,\n",
       "  'loss': 2.0025,\n",
       "  'step': 400},\n",
       " {'epoch': 2.589063345966432,\n",
       "  'eval_loss': 1.9013824462890625,\n",
       "  'eval_runtime': 127.6578,\n",
       "  'eval_samples_per_second': 308.653,\n",
       "  'eval_steps_per_second': 4.825,\n",
       "  'step': 450},\n",
       " {'epoch': 2.87781988810684,\n",
       "  'grad_norm': 247095.71875,\n",
       "  'learning_rate': 1.4285714285714286e-06,\n",
       "  'loss': 1.9908,\n",
       "  'step': 500},\n",
       " {'epoch': 3.450460205739036,\n",
       "  'grad_norm': 232039.125,\n",
       "  'learning_rate': 3.911290322580646e-06,\n",
       "  'loss': 1.9756,\n",
       "  'step': 600},\n",
       " {'epoch': 3.450460205739036,\n",
       "  'eval_loss': 1.8946179151535034,\n",
       "  'eval_runtime': 127.7768,\n",
       "  'eval_samples_per_second': 308.366,\n",
       "  'eval_steps_per_second': 4.821,\n",
       "  'step': 600},\n",
       " {'loss': 1.967,\n",
       "  'grad_norm': 251069.09375,\n",
       "  'learning_rate': 5.104477611940299e-06,\n",
       "  'epoch': 4.023100523371233,\n",
       "  'step': 700},\n",
       " {'eval_loss': 1.9010854959487915,\n",
       "  'eval_runtime': 127.7159,\n",
       "  'eval_samples_per_second': 308.513,\n",
       "  'eval_steps_per_second': 4.823,\n",
       "  'epoch': 4.31185706551164,\n",
       "  'step': 750},\n",
       " {'loss': 1.9539,\n",
       "  'grad_norm': 233244.140625,\n",
       "  'learning_rate': 2.119402985074627e-06,\n",
       "  'epoch': 4.600613607652049,\n",
       "  'step': 800},\n",
       " {'train_runtime': 10225.5133,\n",
       "  'train_samples_per_second': 173.395,\n",
       "  'train_steps_per_second': 0.085,\n",
       "  'total_flos': 5.439243718454159e+16,\n",
       "  'train_loss': 0.38931653472198835,\n",
       "  'epoch': 5.0,\n",
       "  'step': 870}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history # BEFORE FINAL EVAL!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a6430-d14f-41f2-b8fb-1e6f0acfe818",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_lr = []\n",
    "mlm_loss = []\n",
    "\n",
    "mlm_step = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b062f92a-f245-4258-94b0-0258b30218a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "6\n",
      "9\n",
      "11\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# loss per epoch\n",
    "mlm_epoch = []\n",
    "mlm_loss = []\n",
    "\n",
    "for i in range(len(trainer.state.log_history)):\n",
    "    if 'loss' in trainer.state.log_history[i]:\n",
    "        mlm_epoch.append(trainer.state.log_history[i]['epoch'])\n",
    "        mlm_loss.append(trainer.state.log_history[i]['loss'])\n",
    "    elif 'eval_loss' in trainer.state.log_history[i]:\n",
    "        mlm_epoch.append(trainer.state.log_history[i]['epoch'])\n",
    "        mlm_loss.append(trainer.state.log_history[i]['eval_loss'])\n",
    "        print(i)\n",
    "    elif 'train_loss' in trainer.state.log_history[i]:\n",
    "        mlm_epoch.append(trainer.state.log_history[i]['epoch'])\n",
    "        mlm_loss.append(trainer.state.log_history[i]['train_loss'])\n",
    "        print(i)\n",
    "    #print(log['epoch'])\n",
    "    #if 'eval_loss' in log:\n",
    "        #????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5746f1a2-1909-4e4b-9407-429399c3d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c179b287-dd5e-48c9-a980-6d39c3a20439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "6\n",
      "9\n",
      "11\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# loss per epoch\n",
    "mlm_epoch = []\n",
    "mlm_loss = []\n",
    "\n",
    "for i in range(len(trainer.state.log_history)):\n",
    "    if 'loss' in trainer.state.log_history[i]:\n",
    "        mlm_epoch.append(trainer.state.log_history[i]['epoch'])\n",
    "        mlm_loss.append(trainer.state.log_history[i]['loss'])\n",
    "    elif 'eval_loss' in trainer.state.log_history[i]:\n",
    "        mlm_epoch.append(trainer.state.log_history[i]['epoch'])\n",
    "        mlm_loss.append(trainer.state.log_history[i]['eval_loss'])\n",
    "        print(i)\n",
    "    #print(log['epoch'])\n",
    "    #if 'eval_loss' in log:\n",
    "        #????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d1992be-95a5-496b-9aac-2878cdad8239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 5, 7, 8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "eval_idx = [1, 4, 6, 9, 11, 14]\n",
    "idx = []\n",
    "for i in range(len(trainer.state.log_history)):\n",
    "    if i not in eval_idx and i != 13:\n",
    "        idx.append(i)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0018082-81e6-4d00-bf3b-9753cd7ad63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss per epoch (separate eval and normal)\n",
    "plt.rcParams[\"figure.figsize\"] = (7,4)\n",
    "#plt.plot(mlm_epoch, mlm_loss)\n",
    "#idx = [1, 4, 6, 9, 11]\n",
    "plt.plot([mlm_epoch[x] for x in idx], [mlm_loss[x] for x in idx])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss function for MLM pretraining throughout training epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a6799bd-b5c5-4e1c-a0f3-871806206689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss per epoch eval\n",
    "plt.rcParams[\"figure.figsize\"] = (7,4)\n",
    "#plt.plot(mlm_epoch, mlm_loss)\n",
    "#idx = [1, 4, 6, 9, 11]\n",
    "plt.plot([mlm_epoch[x] for x in eval_idx[:-1]], [mlm_loss[x] for x in eval_idx[:-1]])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss function for MLM pretraining during evaluation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc84f99a-f20d-4d82-a4fe-92afa901fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_mlm_best = RobertaForMaskedLM.from_pretrained(\"checkpoints/speech_roberta_mlm/checkpoint-600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5135a2-4cc5-4e48-8b21-8ee4bb21e6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
